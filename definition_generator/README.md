# Generate your own integration definitions

Learn how to create your own definitions for the New Relic Prometheus integration using our definition generator.

1. [What you need](#Prerequisites)
2. [Build the image](#BuildTheImage)
3. [Generate the definition file](#GenerateDefinitionFile)
4. [What's next?](#Whatsnext)

## Introduction

The definition generator is a Python script that helps generate definition files. Definition files can be used to define metrics and entities for the New Relic Prometheus integration (`nri-prometheus`).
 
The script scrapes Prometheus metrics, translates them to New Relic's format and add them to a definition file. If the endpoint is not reachable, you can use a local file containing Prometheus's output as source.

Here's a sample input file or endpoint output:

```
# HELP node_cooling_device_cur_state Current throttle state of the cooling device
# TYPE node_cooling_device_cur_state gauge
node_cooling_device_cur_state{name="0",type="Processor"} 0
node_cooling_device_cur_state{name="1",type="Processor"} 0
# HELP node_cooling_device_max_state Maximum throttle state of the cooling device
# TYPE node_cooling_device_max_state gauge
node_cooling_device_max_state{name="0",type="Processor"} 0
node_cooling_device_max_state{name="1",type="Processor"} 0
[...]
```

And here's a resulting integration definition generated by the script:

```yaml
service: node
display_name: Node
provider: prometheus
entities:
- name: cooling
  metrics:
  - provider_name: node_cooling_device_cur_state
    description: Current throttle state of the cooling device
    type: gauge
    labels:
    - name
    - type
  - provider_name: node_cooling_device_max_state
    description: Maximum throttle state of the cooling device
    type: gauge
    labels:
    - name
    - type
[...]
```

## 1. <a name='Prerequisites'></a>What you need

You need to meet the following prerequisites:
 - Docker installed and running.
 - You must be able to access an exporter endpoint (or an application exposing Prometheus metrics) from the container. Alternatively, you can access Prometheus metrics saved locally.
 - This repository cloned on your machine.

## 2. <a name='BuildTheImage'></a>Build the image

The script is shipped as a Docker container to provide a standardized environment. When building the image, Docker automatically installs the required libraries and tools.
 
Build the Docker image `definition_generator` locally:

``` bash
# Executed in ./definition_generator folder
$ docker build . -t definition_generator
```

Use the resulting image as a working environment for running the script. 

## 3. <a name='GenerateDefinitionFile'></a>Generate the definition file 
 
The script scrapes Prometheus metrics, translates them to New Relic's format and add them to a definition file. If the endpoint is not reachable, you can use a local file containing Prometheus's output as source.

### Using a Prometheus endpoint

Once you have built the image, you are ready to translate output from the `/metrics` endpoint exposed by Prometheus.

Run the following command to scrape the endpoint directly and save the results to `./definition_generated`:

``` bash
$ docker run  definition_generator ./tools.py parse-prometheus -u http://<url>:<port>/metrics > definition_generated
```
### Using Prometheus output saved locally

If you don't have access to the Prometheus endpoint, save the output locally and run the script with the argument`-f --file-path-prometheus` pointing to the mounted file:

``` bash
$ docker run -v /abs/path/to/file:/input_file definition_generator ./tools.py -v parse-prometheus -f /input_file  > definition_generated
```

For example, run the command from the `./definition_generator` folder and point it to the sample file provided:

``` bash
# Executed in ./definition_generator folder
$ docker run -v $(pwd)/parse_prometheus/sample.prometheus:/input_file definition_generator ./tools.py -v parse-prometheus -f /input_file  > definition_generated
```

## 4. <a name='Whatsnext'></a>What's next?

You now have a definition file, `definition_generated`, with all the metrics associated with the correspondent entities.

Since the Prometheus protocol is quite flexible regarding naming convention, review the file after generating it: In some cases you might have to roll some entities into a single one or remove useless or misleading metrics.

For example, consider this generated RavenDB exporter definition. You can see that many entities are vague or contain only a metric which can be grouped under a unique entity, `node`:

```yaml
service: ravendb
display_name: Ravendb
provider: prometheus
entities:
  - name: is
    metrics:
    - provider_name: ravendb_is_leader
      description: If 1, then node is the cluster leader, otherwise 0
      type: gauge
  - name: mapindex
    metrics:
    - provider_name: ravendb_mapindex_indexed
      description: Server-wide map index indexed count
      type: counter
  - name: mapreduceindex
    metrics:
    - provider_name: ravendb_mapreduceindex_mapped
      description: Server-wide map-reduce index mapped count
      type: counter
```

Once you've reviewed the file, rename it according to the technology monitored, place it in the proper folder, and open a PR describing which was the exporter you used to generate the file and its version.
